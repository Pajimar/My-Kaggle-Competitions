{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Competicion Dog Breed Identification : https://www.kaggle.com/c/dog-breed-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogbreed.zip\tsample_submission.csv\t   test      train.zip\r\n",
      "labels.csv\tsample_submission.csv.zip  test.zip  Untitled.ipynb\r\n",
      "labels.csv.zip\tsub\t\t\t   tmp\r\n",
      "models\t\tsubmission.csv\t\t   train\r\n"
     ]
    }
   ],
   "source": [
    "PATH = \"data/dogbreed/\"\n",
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "arch = resnext101_64\n",
    "bs=16\n",
    "label_csv = f'{PATH}labels.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(list(open(label_csv)))-1\n",
    "# random 20% indexes from range 1-n (total labels)\n",
    "val_idxs = get_cv_idxs(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_csv(label_csv)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, \n",
    "                       max_zoom=1.1)\n",
    "data = ImageClassifierData.from_csv(PATH, 'train', \n",
    "                 f'{PATH}labels.csv', test_name='test', \n",
    "                 val_idxs=val_idxs, suffix='.jpg', tfms=tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos automatizar esto mismo en una funcion que pida sz (tamaño de la imagen) y bs (tamaño del batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz, bs):\n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on,\n",
    "                           max_zoom=1.1)\n",
    "    data = ImageClassifierData.from_csv(PATH, 'train', \n",
    "               f'{PATH}labels.csv', test_name='test', num_workers=4,\n",
    "               val_idxs=val_idxs, suffix='.jpg', tfms=tfms, bs=bs)\n",
    "    return data if sz>300 else data.resize(340, 'tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el objeto data y la CNN (la instancia learn). Establecemos precompute=True: Esto significa que durante la primera epoch (una epoch consiste en pasar por todas las imagenes del data set una vez), se calcularán las activaciones de todas las capas. ¿Por qué solo durante la primera? Empiezo por el principio .... \n",
    "\n",
    "Hemos cargado una arquitectura de red concreta, esto significa que ademas de tener una disposicion de capas de neuronas, tenemos los pesos de la red con unos valores concretos (aquellos que resultaron de entrenar dicha arquitectura en su momento). Esos pesos (los numeros del kernel) estaban preparados para identficar determinados patrones en las fotos donde la red se entrenó. Lo que nos interesa de la red realmente son esos pesos concretos, y de momento no los vamos a modificar.  \n",
    "\n",
    "Cuando creamos nuestra instancia learn, estamos cargando la arquitectura arch que le pasamos como parametro menos la ultima capa, que en su lugar será construida automáticamente en funcion de las clases que necesitemos predecir (esto se sabe gracias al objeto data, que tambien se pasa como argumento). Para que esa última capa que se construye al final de la red neuronal que hemos cargado sirva de algo, tiene que tener unos datos de entrada (las activaciones de la capa anterior), por eso, debemos computar al menos una vez las activaciones de toda la red, para que haya una entrada a nuestra ultima capa. Podriamos computar las activaciones en cada nueva epoch ... pero ¿tendria esto sentido? las imagenes se repetirian en sucesivas epochs y los pesos tampoco cambiarán por tanto las activaciones (convolucion de la imagen y los pesos del kernel) produciran las mismas activaciones en la primera capa, y al convolucionar estas con los kernels de la siguiente capa (y asi sucesivamente) tampoco cambiaran las siguientes activaciones.\n",
    "\n",
    "En resumen, hacemos precompute=True para tener una entrada a nuestra ultima capa y poder entrenar los pesos de esa ultima capa cuando hagamos learn.fit(). Computar activaciones en sucesivas epochs no cambia nada y es computacionalmente costoso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a07899369d4b49ac41e91d89dcc5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Se crea la carpeta 340 dentro de temp; dentro de 340 aparecen los subfolders models y temp, pero aun estan vacias\"\"\"\n",
    "data = get_data(224, bs)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo, con learning rate = 0.01, durante 5 epochs. El por qué de ese valor de learning rate estará explicado en la libreta que habla de 'cyclical learning rates', un paper publicado en 2015, que explica como encontrar un valor apropiado para este parametro en funcion de lo rápido que decrece la función de pérdida entrenando con ese valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2dce2a4bf449fe8e52623ae07b5287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.634946   0.354258   0.897461  \n",
      "    1      0.396411   0.319496   0.90332                      \n",
      "    2      0.337316   0.289285   0.912598                    \n",
      "    3      0.235152   0.327542   0.905599                     \n",
      "    4      0.214835   0.311772   0.911133                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3117722, 0.9111328125]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(0.01,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69a2442f1a64465a017ef07d90a14a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.281992   0.250768   0.919434  \n",
      "    1      0.292057   0.240535   0.922363                    \n",
      "    2      0.208027   0.250002   0.919922                    \n",
      "    3      0.220461   0.250099   0.911133                    \n",
      "    4      0.21644    0.249182   0.913574                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24918243, 0.91357421875]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.precompute = False\n",
    "learn.fit(1e-2, 5, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overfitting (trn_loss << val_loss), osea problema de varianza o de generalizacion. Aumentaremos el tamaño de las imagenes para prevenir overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un buen punto para guardar. Hay que tener en cuenta lo siguiente antes: cargar un modelo da problemas si lo guardamos con precompute=True y lo cargamos con precompute=False y viceversa. Porque uno de los archivos (el que se guarda o el que se recupera) tendria activaciones distintas (precompute=False) en todas las capas de la red, y el otro tendria las activaciones (menos la de la primera capa) de la arquitectura tal cual la cargamos. Asi que guardaremos el modelo (el modelo guardado se queda en 340/tmp/models) con precompute=False\n",
    "\n",
    "Cuando volvamos a conectar con la notebook (o hagamos restart en el kernel si se queda atascado en algun momento), es importante crear una nueva instancia del objeto learn pero con precompute=False : learn = ConvLearner.pretrained(arch, data, precompute = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('dogbreed_resnext10164_pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed8148430204ee392a2ff0aed23cb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# encendemos de nuevo el kernel. Hacemos todos los imports y demas hasta la celda donde creamos el objeto data y learn\n",
    "data = get_data(224, bs)\n",
    "# preparamos una instancai de ConvLearner con precompute = False\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=False)\n",
    "learn.load('dogbreed_resnext10164_pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya podemos seguir con el entrenamiento. Una forma de reducir overfitting es aumentando el tamaño de las imagénes: en cierto sentido son imágenes distintas que requerirán ajustar los pesos y 'despegarse' un poco de la distribucion de imagenes original para tener estas en cuenta, pero por otra parte, son imagénes muy parecidas; un perro de X raza seguirá siendo de esa raza despues de aumentar la imágen, seguirá teniendo los mismos colores, la misma forma etc, asi que esto no hará que nuestros pesos se desvien mucho de su valor actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daee7168ba8445e8ad3b863e20ab0d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learn.set_data(get_data(299, bs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos durante 3 ciclos, cada uno de los cuales durará un epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f947af166a945ee8084c03168e9c8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.24987    0.240885   0.922852  \n",
      "    1      0.252596   0.262771   0.915039                    \n",
      "    2      0.240615   0.256994   0.920898                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25699446, 0.9208984375]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-2, 3, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El trn_loss y val_loss se van reduciendo a la vez, esto es buena señal. Buen momento para volver a guardar el modelo, estos entrenamientos ya van tardando más ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('dogbreed_resnext10164_pre')\n",
    "# a la hora de cargar, cargarlo preparando el objeto learn con todas las caracteristicas que tenia el modelo antes de hacer el save: precompute=False, data=get_data(299,bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa901ae9e2d4106a4dafd3ecffe87ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# cargamos el modelo\n",
    "data = get_data(299,bs)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=False)\n",
    "learn.load('dogbreed_resnext10164_pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuamos el entrenamiento: 3 ciclos, cada uno un epoch, como antes. La novedad ahora es que cada nuevo ciclo tendra 2 veces más epochs que el anterior (cycle_mult = 2). Es decir:\n",
    "\n",
    "primer ciclo: 1 epoch\n",
    "segundo ciclo : 2 * 1 = 2 epochs\n",
    "tercer ciclo : 2 * 2 = 4 epochs\n",
    "\n",
    "En total 7 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d01a1f54943463bb2f1fdf311e563e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.183962   0.25741    0.925293  \n",
      "    1      0.19902    0.252502   0.922363                    \n",
      "    2      0.180208   0.240001   0.922852                    \n",
      "    3      0.183189   0.255142   0.921387                    \n",
      "    4      0.199824   0.272928   0.925781                    \n",
      "    5      0.153954   0.256319   0.922363                    \n",
      "    6      0.1296     0.248201   0.927572                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2482013, 0.9275716147385538]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-2, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('dogbreed_resnext10164_postcycle_mult')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b51fcdee8c44349a34621907883b466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = get_data(299,bs)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=False)\n",
    "learn.load('dogbreed_resnext10164_postcycle_mult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cuando hago TTA en un modelo, lo guardo y luego lo vuelvo a cargar, quizas para mejorarlo y cuando acabo vuelvo a hacer\n",
    "TTA a la hora de conseguir predicciones tarda muchisimo en ejecutarse, asi que como ya guardé\n",
    "un modelo con TTA, ahora hago las predicciones sobre el test sin ir generando versiones nuevas de fotos y predecir con una media\n",
    "(que es llo que hace TTA)\n",
    "\n",
    "Interiormente learn.predict y learn.TTA llaman a predict_with_targs (en el caso de predict, devuelve solo log_preds, en el caso\n",
    "de TTA, devuelve tambien los targets)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta libreria esta construida encima de pytorch, que suele devolver el logaritmo de las predicciones en lugar de las probabilidades en sí. Por eso, una vez llamamos a predict (sobre el test set) para obetener 120 (log de) predicciones (por las 120 clases) sobre cada una de los 10357 fotos, es necesario despues hacer la exponencial de dichos logaritmos para obetener las probabilidades finales. La biblioteca numpy permite hacer esto 'element-wise' (la exponencial de cada una de las salidas de predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds = learn.predict(is_test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.exp(log_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10357, 120)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta biblioteca implementa tambien el metodo TTA (test time augmentation). Lo que hace esta funcion es que por cada foto del test/validation set, hace 4 transformaciones (ligeras variaciones), usa el modelo para predecir la clasificacion sobre las 5 fotos (la original y las 4 variaciones) y toma una media de la clasificacion. Es decir, basicamente vamos tomando una por una las fotos del validation/test set, y creando 4 transformaciones cada vez, teniendo las 5 en cuenta clasificamos la origianal y pasamos a la siguiente. La forma de usarla seria la misma:\n",
    "\n",
    "log_preds, y = learn.TTA(is_test = True) <--- sobre el test set, sin este argumento seria sobre el validation set\n",
    "probs = np.mean(np.exp(log_preds),0) <--- sacamos probabilidades y la media de las 5 fotos. Esto para todo el test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quedan cosas por explicar (encontrar un buen learning rate siguiendo el paper antes mencionado), pero abstrayendo algunos detalles y siguiendo esta implementación sin mayor complicación, se puede conseguir una posicion de 385/1286 en el momento de subirlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/score.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
